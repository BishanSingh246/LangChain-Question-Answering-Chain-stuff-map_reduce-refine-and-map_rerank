{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.0.206 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 1)) (0.0.206)\n",
      "Requirement already satisfied: openai==0.27.8 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 2)) (0.27.8)\n",
      "Requirement already satisfied: chromadb==0.3.26 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from -r requirements.txt (line 3)) (0.3.26)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (1.4.48)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (0.5.7)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.13 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (0.0.16)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (1.10.9)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (2.30.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain==0.0.206->-r requirements.txt (line 1)) (8.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai==0.27.8->-r requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (1.5.3)\n",
      "Requirement already satisfied: hnswlib>=0.7 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (0.6.3)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (0.8.1)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (0.96.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (0.22.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (4.5.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (1.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (0.13.3)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.26->-r requirements.txt (line 3)) (7.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.206->-r requirements.txt (line 1)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.206->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.206->-r requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.206->-r requirements.txt (line 1)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.206->-r requirements.txt (line 1)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.206->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26->-r requirements.txt (line 3)) (2023.5.7)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26->-r requirements.txt (line 3)) (1.26.15)\n",
      "Requirement already satisfied: pytz in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26->-r requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: zstandard in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26->-r requirements.txt (line 3)) (0.21.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.26->-r requirements.txt (line 3)) (4.3.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.206->-r requirements.txt (line 1)) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.206->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.206->-r requirements.txt (line 1)) (0.8.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi>=0.85.1->chromadb==0.3.26->-r requirements.txt (line 3)) (0.27.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (23.5.9)\n",
      "Requirement already satisfied: packaging in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (4.23.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.3->chromadb==0.3.26->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.26->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.26->-r requirements.txt (line 3)) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.26->-r requirements.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2->langchain==0.0.206->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.206->-r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai==0.27.8->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26->-r requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26->-r requirements.txt (line 3)) (0.5.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26->-r requirements.txt (line 3)) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.26->-r requirements.txt (line 3)) (11.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.26->-r requirements.txt (line 3)) (3.7.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.206->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.26->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb==0.3.26->-r requirements.txt (line 3)) (1.0.4)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\mr darklord\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.26->-r requirements.txt (line 3)) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'Enter your api key here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# loader = TextLoader(\"./state_of_the_union.txt\", encoding=\"utf-8\")\n",
    "# state_of_the_union = loader.load()\n",
    "# print(state_of_the_union)\n",
    "\n",
    "with open(\"./state_of_the_union.txt\",encoding=\"utf-8\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_text(state_of_the_union)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))]).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did the president say about Justice Breyer\"\n",
    "docs = docsearch.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "\n",
    "If you just want to get started as quickly as possible, this is the recommended way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The president said that Justice Breyer is an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court, and thanked him for his service.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Stuff Chain\n",
    "\n",
    "\n",
    "The stuff chain is a simple way to combine multiple documents together and feed them into a language model. It works best when the documents are short and only a few of them are used at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' The president said that Justice Breyer is an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court, and thanked him for his service.'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Prompts\n",
    "\n",
    "You can also use your own prompts with this chain. In this example, we will respond in Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' Il presidente ha detto che Justice Breyer ha dedicato la sua vita al servizio di questo paese e ha ringraziato per il suo servizio.'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in Italian:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\", prompt=PROMPT)\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The map_reduce Chain\n",
    "\n",
    "\n",
    "The map reduce process involves two steps: mapping and reducing. First, each document goes through a series of actions called the LLM chain individually (map). The output of these actions is treated as a new document. Then, all the new documents are combined together to create a final result (reduce). If needed, the mapped documents can be compressed to fit in the combine step, and this compression can be done repeatedly if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': ' The president said that Justice Breyer is an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court, and thanked him for his service.'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Steps\n",
    "\n",
    "We can also return the intermediate steps for map_reduce chains, should we want to inspect them. This is done with the return_map_steps variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_reduce\", return_map_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [' \"Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\"',\n",
       "  ' A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.',\n",
       "  ' None',\n",
       "  ' None'],\n",
       " 'output_text': ' The president said that Justice Breyer is an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court, and thanked him for his service.'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Prompts\n",
    "\n",
    "You can also use your own prompts with this chain. In this example, we will respond in Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [\"\\nStasera vorrei onorare qualcuno che ha dedicato la sua vita a servire questo paese: il giustizia Stephen Breyer - un veterano dell'esercito, uno studioso costituzionale e un giustizia in uscita della Corte Suprema degli Stati Uniti. Giustizia Breyer, grazie per il tuo servizio.\",\n",
       "  '\\nNessun testo pertinente.',\n",
       "  \" Non c'è testo pertinente per rispondere alla domanda.\",\n",
       "  ' Non ha detto nulla riguardo a Justice Breyer.'],\n",
       " 'output_text': ' Non ha detto nulla riguardo a Justice Breyer.'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_prompt_template = \"\"\"Use the following portion of a long document to see if any of the text is relevant to answer the question. \n",
    "Return any relevant text translated into italian.\n",
    "{context}\n",
    "Question: {question}\n",
    "Relevant text, if any, in Italian:\"\"\"\n",
    "QUESTION_PROMPT = PromptTemplate(\n",
    "    template=question_prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "combine_prompt_template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer italian. \n",
    "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "\n",
    "QUESTION: {question}\n",
    "=========\n",
    "{summaries}\n",
    "=========\n",
    "Answer in Italian:\"\"\"\n",
    "COMBINE_PROMPT = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"summaries\", \"question\"]\n",
    ")\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_reduce\", return_map_steps=True, question_prompt=QUESTION_PROMPT, combine_prompt=COMBINE_PROMPT)\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Size\n",
    "\n",
    "When using the map_reduce chain, one thing to keep in mind is the batch size you are using during the map step. If this is too high, it could cause rate limiting errors. You can control this by setting the batch size on the LLM used. Note that this only applies for LLMs with this parameter. Below is an example of doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(batch_size=5, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The refine Chain\n",
    "\n",
    "The refine documents chain uses a looping process to update its answer by analyzing each document one at a time. This method is good for tasks that involve many documents but has the drawback of making more calls to the model. It may not work well when documents refer to each other or when detailed information is needed from multiple documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': '\\n\\nThe president said that he wanted to honor Justice Breyer for his dedication to serving the country, his legacy of excellence, and his commitment to advancing liberty and justice, while also emphasizing the importance of competition and the need to go after criminals who have stolen relief money meant for small businesses and millions of Americans. He also expressed his support for the LGBTQ+ community and the need to pass the Equality Act, as well as his commitment to strengthening the Violence Against Women Act. Additionally, he offered a Unity Agenda for the Nation to beat the opioid epidemic.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Steps\n",
    "\n",
    "We can also return the intermediate steps for refine chains, should we want to inspect them. This is done with the return_refine_steps variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"refine\", return_refine_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['\\nThe president said that he wanted to honor Justice Breyer for his dedication to serving the country and his legacy of excellence.',\n",
       "  '\\nThe president said that he wanted to honor Justice Breyer for his dedication to serving the country, his legacy of excellence, and his commitment to advancing liberty and justice.',\n",
       "  '\\nThe president said that he wanted to honor Justice Breyer for his dedication to serving the country, his legacy of excellence, and his commitment to advancing liberty and justice, while also emphasizing the importance of competition and the need to go after criminals who have stolen relief money meant for small businesses and millions of Americans.',\n",
       "  '\\n\\nThe president said that he wanted to honor Justice Breyer for his dedication to serving the country, his legacy of excellence, and his commitment to advancing liberty and justice, while also emphasizing the importance of competition and the need to go after criminals who have stolen relief money meant for small businesses and millions of Americans. He also expressed his support for the LGBTQ+ community and the need to pass the Equality Act, as well as his commitment to strengthening the Violence Against Women Act. Additionally, he offered a Unity Agenda for the Nation to beat the opioid epidemic.'],\n",
       " 'output_text': '\\n\\nThe president said that he wanted to honor Justice Breyer for his dedication to serving the country, his legacy of excellence, and his commitment to advancing liberty and justice, while also emphasizing the importance of competition and the need to go after criminals who have stolen relief money meant for small businesses and millions of Americans. He also expressed his support for the LGBTQ+ community and the need to pass the Equality Act, as well as his commitment to strengthening the Violence Against Women Act. Additionally, he offered a Unity Agenda for the Nation to beat the opioid epidemic.'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Prompts\n",
    "\n",
    "You can also use your own prompts with this chain. In this example, we will respond in Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['\\nIl presidente ha detto che Justice Breyer ha dedicato la sua vita al servizio di questo paese e ha reso omaggio al suo servizio.',\n",
       "  \"\\nIl presidente ha detto che Justice Breyer ha dedicato la sua vita al servizio di questo paese, ha ricevuto un ampio sostegno da parte della Fraternal Order of Police e di ex giudici nominati da democratici e repubblicani, e ha reso omaggio al suo servizio. Ha anche sottolineato l'importanza di avanzare la libertà e la giustizia, sia attraverso la sicurezza delle frontiere che attraverso la risoluzione del sistema di immigrazione.\",\n",
       "  \"\\n\\nIl presidente ha detto che Justice Breyer ha dedicato la sua vita al servizio di questo paese, ha ricevuto un ampio sostegno da parte della Fraternal Order of Police e di ex giudici nominati da democratici e repubblicani, e ha reso omaggio al suo servizio. Ha anche sottolineato l'importanza di avanzare la libertà e la giustizia, sia attraverso la sicurezza delle frontiere che attraverso la risoluzione del sistema di immigrazione, e di lottare contro la criminalità che ha rubato miliardi di dollari di aiuti destinati alle piccole imprese e a milioni di americani. Ha inoltre annunciato che il Dipartimento di Giustizia nominerà un procuratore capo per la frode pandemica.\",\n",
       "  \"\\n\\nIl presidente ha detto che Justice Breyer ha dedicato la sua vita al servizio di questo paese, ha ricevuto un ampio sostegno da parte della Fraternal Order of Police e di ex giudici nominati da democratici e repubblicani, e ha reso omaggio al suo servizio. Ha anche sottolineato l'importanza di avanzare la libertà e la giustizia, sia attraverso la sicurezza delle frontiere che attraverso la risoluzione del sistema di immigrazione, e di lottare contro la criminalità che ha rubato miliardi di dollari di aiuti destinati alle piccole imprese e a milioni di americani. Ha inoltre annunciato che il Dipartimento di Giustizia nominerà un procuratore capo per la frode pandemica, e ha espresso il suo sostegno alla comunità LGBTQ+ invitando a portare l'Equality Act al suo\"],\n",
       " 'output_text': \"\\n\\nIl presidente ha detto che Justice Breyer ha dedicato la sua vita al servizio di questo paese, ha ricevuto un ampio sostegno da parte della Fraternal Order of Police e di ex giudici nominati da democratici e repubblicani, e ha reso omaggio al suo servizio. Ha anche sottolineato l'importanza di avanzare la libertà e la giustizia, sia attraverso la sicurezza delle frontiere che attraverso la risoluzione del sistema di immigrazione, e di lottare contro la criminalità che ha rubato miliardi di dollari di aiuti destinati alle piccole imprese e a milioni di americani. Ha inoltre annunciato che il Dipartimento di Giustizia nominerà un procuratore capo per la frode pandemica, e ha espresso il suo sostegno alla comunità LGBTQ+ invitando a portare l'Equality Act al suo\"}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_prompt_template = (\n",
    "    \"The original question is as follows: {question}\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing answer\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better \"\n",
    "    \"answer the question. \"\n",
    "    \"If the context isn't useful, return the original answer. Reply in Italian.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"existing_answer\", \"context_str\"],\n",
    "    template=refine_prompt_template,\n",
    ")\n",
    "\n",
    "\n",
    "initial_qa_template = (\n",
    "    \"Context information is below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the question: {question}\\nYour answer should be in Italian.\\n\"\n",
    ")\n",
    "initial_qa_prompt = PromptTemplate(\n",
    "    input_variables=[\"context_str\", \"question\"], template=initial_qa_template\n",
    ")\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"refine\", return_refine_steps=True,\n",
    "                     question_prompt=initial_qa_prompt, refine_prompt=refine_prompt)\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The map-rerank Chain\n",
    "\n",
    "The map re-rank documents chain uses a prompt to evaluate documents and find the best answer, considering both the completion of a task and the certainty of the response. It returns the response with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_rerank\", return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mr Darklord\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py:303: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about Justice Breyer\"\n",
    "results = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The President thanked Justice Breyer for his service and honored him for dedicating his life to serve the country.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': ' The President thanked Justice Breyer for his service and honored him for dedicating his life to serve the country.',\n",
       "  'score': '100'},\n",
       " {'answer': ' This document does not answer the question', 'score': '0'},\n",
       " {'answer': ' This document does not answer the question', 'score': '0'},\n",
       " {'answer': ' This document does not answer the question', 'score': '0'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"intermediate_steps\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Prompts\n",
    "\n",
    "You can also use your own prompts with this chain. In this example, we will respond in Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': [{'answer': ' Il presidente ha detto che Justice Breyer ha dedicato la sua vita a servire questo paese.',\n",
       "   'score': '100'},\n",
       "  {'answer': \" Il presidente ha detto che Justice Breyer è un costruttore di consenso che ha ricevuto un ampio sostegno da parte dell'Ordine Fraterno della Polizia e di ex giudici nominati da democratici e repubblicani.\",\n",
       "   'score': '50'},\n",
       "  {'answer': ' Non so.', 'score': '0'},\n",
       "  {'answer': ' Non so.', 'score': '0'}],\n",
       " 'output_text': ' Il presidente ha detto che Justice Breyer ha dedicato la sua vita a servire questo paese.'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "output_parser = RegexParser(\n",
    "    regex=r\"(.*?)\\nScore: (.*)\",\n",
    "    output_keys=[\"answer\", \"score\"],\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "In addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\n",
    "\n",
    "Question: [question here]\n",
    "Helpful Answer In Italian: [answer here]\n",
    "Score: [score between 0 and 100]\n",
    "\n",
    "Begin!\n",
    "\n",
    "Context:\n",
    "---------\n",
    "{context}\n",
    "---------\n",
    "Question: {question}\n",
    "Helpful Answer In Italian:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    output_parser=output_parser,\n",
    ")\n",
    "\n",
    "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"map_rerank\", return_intermediate_steps=True, prompt=PROMPT)\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document QA with sources\n",
    "\n",
    "We can also perform document QA and return the sources that were used to answer the question. To do this we'll just need to make sure each document has a \"source\" key in the metadata, and we'll use the load_qa_with_sources helper to construct our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))])\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': \" The president thanked Justice Breyer for his service and mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer's legacy of excellence.\\nSOURCES: 31-pl\"}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "981cc7f460dc3ad49f1bbaadde9c38788d3b59d0c49edfce12f416a560823fea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
